#!/usr/bin/env python

# File:         extension-4
# Authors:      Casey Davis, Harry Okun, Brian Sladek, Ayla Taylor
# Description:  Extension to our baseline tagger which refines the tag outputs
#               by first calculating the probability that each unique word will
#               have a given tag, then reassigns "X" tags if the probability of
#               the new tag is above a certain threshold.

import operator
import optparse
import sys
from collections import defaultdict

optparser = optparse.OptionParser()
optparser.add_option("-i", "--input-data", dest="input_data", default="data/comtrans.g", help="Input file to tag")
optparser.add_option("-e", "--english-refs", dest="english_refs", default="data/refs.e", help="POS-tagged English refs")
optparser.add_option("-a", "--alignments", dest="alignments", default="data/comtrans.a", help="German-English alignment file")
optparser.add_option("-t", "--threshold", dest="threshold", default="0.0", type=float, help="Threshold for reassigning most probable tag")
(opts, _) = optparser.parse_args()

input_file = open(opts.input_data)
english_refs_file = open(opts.english_refs)
alignment_file = open(opts.alignments)
threshold = opts.threshold

tag_probabilities = defaultdict(lambda: defaultdict(float))

sys.stderr.write("Reading German input...\n")
all_german_sentences = []
for sentence in input_file.readlines():
    words = []
    sentence = sentence.strip()
    for word in sentence.split(" "):
        words.append(word)
    all_german_sentences.append(words)

sys.stderr.write("Reading tagged English input...\n")
all_english_tags = []
for sentence in english_refs_file.readlines():
    word_tag_pairs = []
    sentence = sentence.strip()
    for tagged_word in sentence.split(" "):
        (word, tag) = tagged_word.split(":::")
        word_tag_pairs.append((word, tag))
    all_english_tags.append(word_tag_pairs)

sys.stderr.write("Reading alignment file...\n")
all_alignments = []
for sentence_alignment in alignment_file.readlines():
    alignment_pairs = []
    sentence_alignment = sentence_alignment.strip()
    for word_alignment in sentence_alignment.split(" "):
        (german_index, english_index) = word_alignment.split("-")
        alignment_pairs.append((int(german_index), int(english_index)))
    all_alignments.append(alignment_pairs)

sys.stderr.write("Tagging...\n")
german_tags = []
for i in xrange(len(all_alignments)):
    sentence_alignment = all_alignments[i]
    german_sentence = all_german_sentences[i]
    tagged_english_sentence = all_english_tags[i]
    tagged_german_sentence = []
    for j in xrange(len(german_sentence)):
        word = german_sentence[j]
        tag = "X"
        for word_alignment in sentence_alignment:
            if word_alignment[0] == j:
                tag = tagged_english_sentence[word_alignment[1]][1]
                break
        tag_probabilities[word][tag] += 1
        tagged_german_sentence.append((word, tag))
    german_tags.append(tagged_german_sentence)

# Normalize word-tag counts
for (word, possible_tags_for_word) in tag_probabilities.iteritems():
    total = float(sum(possible_tags_for_word.values()))
    for (tag, count) in possible_tags_for_word.iteritems():
        possible_tags_for_word[tag] = count / total

for sentence in german_tags:
    tagged_sentence = ""
    for (word, tag) in sentence:
        if tag == "X":
            try:
                (new_tag, prob) = max(tag_probabilities[word].iteritems(), key=operator.itemgetter(1)) # Find most probable tag
                if prob > threshold: # If the new tag is really likely, reassign
                    tag = new_tag
            except KeyError:
                pass
        tagged_sentence += word + ":::" + tag + " "
    sys.stdout.write(tagged_sentence + "\n")

input_file.close()
english_refs_file.close()
alignment_file.close()
sys.stderr.write("Done\n")
